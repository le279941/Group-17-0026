---
title: "Coding Assignment 3"
author: "Team 16"
date: "Due: 2023-12-09 23:59"
output: 
  pdf_document:
    toc: true
---

```{r setup, include=FALSE}
options(repos = c(CRAN = "https://cran.rstudio.com"))
library(readr)
library(tinytex)
library(readxl)
library(dplyr)
library(ggplot2)
library(lmtest)
library(car)
library(plotly)
library(gt)
library(gtsummary)
library(tidyr)
tinytex::install_tinytex(force = TRUE)
knitr::opts_chunk$set(echo = TRUE)
```

A Florida health insurance company wants to predict annual claims for individual clients. The company pulls a random sample of 100 customers. The owner wishes to charge an actuarially fair premium to ensure a normal rate of return. The owner collects all of their current customer's health care expenses from the last year and compares them with what is known about each customer's plan.

The data on the 100 customers in the sample is as follows:

-   Charges: Total medical expenses for a particular insurance plan (in dollars)
-   Age: Age of the primary beneficiary
-   BMI: Primary beneficiary's body mass index (kg/m2)
-   Female: Primary beneficiary's birth sex (0 = Male, 1 = Female)
-   Children: Number of children covered by health insurance plan (includes other dependents as well)
-   Smoker: Indicator if primary beneficiary is a smoker (0 = non-smoker, 1 = smoker)
-   Cities: Dummy variables for each city with the default being Sanford

Answer the following questions using complete sentences and attach all output, plots, etc. within this report.

```{r dataset, include=TRUE}
# Bring in the dataset here.
Insurance_Data_Group16 <- read_csv("~/GitHub/ECO6416_Group16/Data/Insurance_Data_Group16.csv", 
                                   show_col_types = FALSE)
```

## Question 1

Randomly select 30 observations from the sample and exclude from all modeling (i.e. n=47). Provide the summary statistics (min, max, std, mean, median) of the quantitative variables for the 70 observations.

```{r q1}
set.seed(123456)
index <- sample(seq_len(nrow(Insurance_Data_Group16)), size = 30)
train <- Insurance_Data_Group16[-index,]
test <- Insurance_Data_Group16[index,]
#I am going to round the values to specific decimals for a cleaner presentation
numeric_vars <- sapply(train, is.numeric)
summary_train <- summary(train[, numeric_vars])
rounded_summary_train <- lapply(summary_train, function(x) if(is.numeric(x)) round(x,2) else x)
print(rounded_summary_train)
```

## Question 2

Provide the correlation between all quantitative variables

```{r}
quantitative_vars <- train[, c("Charges", "Age", "BMI", "Children")]

correlation_matrix <- cor(quantitative_vars, use = "complete.obs")
correlation_matrix
```

## Question 3

Run a regression that includes all independent variables in the data table. Does the model above violate any of the Gauss-Markov assumptions? If so, what are they and what is the solution for correcting?

```{r}
model <- lm(Charges ~ ., data = train)
model_summary <- summary(model)
print(model_summary)
```

**Independence:**

```{r}
# Independence (Durbin-Watson Test)
dwtest(model)
```

The residuals should be independent of each other, which means there should be no correlation between them. Positive autocorrelation in residuals suggests that consecutive errors may be correlated. For example, *if medical expenses increase at a different rate for smokers vs non-smokers as they age*, it may lead to autocorrelation. The Durbin-Watson test result shows a DW value of 2.0828 with a p-value of 0.6532, which suggests that there is no significant autocorrelation, and the independence assumption is not violated.

**Homoscedasticity:**

```{r}
# Homoscedasticity (Constant Variance of Residuals)
bptest_result <- bptest(model)
print(bptest_result)
```

The residuals should have a constant variance, which can be tested with the Non-constant Variance Score Test. The presence of heteroscedasticity implies unequal variance of residuals. This might be influenced *by varying patterns in medical expenses for different groups, like smokers vs. non-smokers or certain age ranges*. A non-significant p-value indicates that the assumption of homoscedasticity is not violated. The test result has a p-value of 0.7691, which is above the common alpha level of 0.05, suggesting a possible, but not definitive, violation of homoscedasticity. For the potential homoscedasticity issue, we may consider utilizing robust standard errors or transforming the response variable.

**Multicollinearity:**

```{r}
# Multicollinearity (Variance Inflation Factors)
vif(model)
```

The predictors should not be perfectly collinear. The VIF values are all well below 5, indicating that multicollinearity is not a concern for this model.

**Normality of Error Terms:**

```{r}
#Normality of Error Terms
qqnorm(residuals(model), col = "lightblue")
qqline(residuals(model), col = "pink")

shapiro.test(residuals(model))
```

Looking into specific relationships between other variables may uncover patterns affecting normality. For instance, *if the impact of age on medical expenses differs significantly between genders*, it may contribute to non-normality. The Q-Q plot analysis indicates a violation of the normality assumption of the Gauss-Markov theorem. While the central part of the residuals aligns well with the normal line, indicating appropriate behavior for the bulk of the data, there is a clear deviation in the tails---especially on the right---suggesting a positive skew in the distribution of residuals. This is corroborated by a Shapiro-Wilk test that returned a p-value of 1.06Ã—10\^(-)6, which is significantly below the 0.05 threshold, further confirming the non-normality of residuals. To correct this, one could consider transforming the dependent variable, dealing with outliers, incorporating omitted variables, or using a different type of regression model such as a generalized linear model that does not assume normal distribution of errors.

## Question 4

Implement the solutions from question 3, such as data transformation, along with any other changes you wish. Use the sample data and run a new regression. How have the fit measures changed? How have the signs and significance of the coefficients changed?

```{r q4}
# Model 1: Log Transformation of Charges
train$log_charges <- log(train$Charges)
model_log <- lm(log_charges ~ ., data = train)
summary(model_log)

# Model 2: Square Root Transformation of Charges
train$sqrt_charges <- sqrt(train$Charges)
model_sqrt <- lm(sqrt_charges ~ ., data = train)
summary(model_sqrt)

# Model 3: Interaction Term between Age and BMI
train$interaction_term <- train$Age * train$BMI
model_interaction <- lm(Charges ~ . + interaction_term, data = train)
summary(model_interaction)

# Predictions for each model
predictions_model1 <- exp(predict(model_log))
predictions_model2 <- predict(model_sqrt)^2
predictions_model3 <- predict(model_interaction)
# Combine actual and predicted values
scatter_data <- data.frame(
Actual = train$Charges,
Model1 = predictions_model1,
Model2 = predictions_model2,
Model3 = predictions_model3
)
# Scatterplot
plot(scatter_data$Actual, scatter_data$Model1, col = "pink", main = "Model Comparison", xlab = "Actual Charges", ylab = "Predicted Charges")
points(scatter_data$Actual, scatter_data$Model2, col = "lightblue")
points(scatter_data$Actual, scatter_data$Model3, col = "lightgreen")
legend("topright", legend = c("Model 1", "Model 2", "Model 3"), col = c("pink", "lightblue", "lightgreen"), pch = 1)

# Natural Log of Charges
par(mfrow = c(1, 2))
hist(train$Charges, col = "skyblue", main = "Distribution of Charges", xlab = "Charges", ylab = "Frequency") # Before
train$lnCharges <- log(train$Charges)
hist(train$lnCharges, col = "lightgreen", main = "Distribution of Log Charges", xlab = "Log Charges", ylab = "Frequency") # After
```

Let's break down the fit measures, signs & significance of coefficients by looking at each model separately. (Note - we are going to focus on the adjusted R-squared because it accounts for the number of predictors in the model, and penalizes the inclusion of unnecessary predictors that do not contribute to explaining variance.)

-   **Model 1: Transformation of Charges**\
    The adjusted R-squared has decreased from 0.9953 to 0.9989, suggesting the model explains less variability in the transformed data. The signs and significance of the coefficients have changed, and their interpretation is based on the log-transformed charges.

-   **Model 2: Square-Root Transformation of Charges**\
    The adjusted R-squared has increased to 0.9989, and while it is a better fit than the original model, Model 1 is still a better fit overall. The signs and significance of the coefficients here have changed and their interpretation is based on the square-root transformed charges.

-   **Model 3: Interaction Term Between Age & BMI**\
    The adjusted R-squared has increased to 0.9965, proving good fit to the data. The signs and significance have changed due to the inclusion of the interaction term; the interpretation involves the joint effect of Age & BMI to medical expenses.

## Question 5

Use the 30 withheld observations and calculate the performance measures for your best two models. Which is the better model? (remember that "better" depends on whether your outlook is short or long run)

```{r q5}
# Test Data
set.seed(123456)
index <- sample(seq_len(nrow(Insurance_Data_Group16)), size = 30)

train <- Insurance_Data_Group16[-index,]
test <- Insurance_Data_Group16[index,]

# Scale Charges in Test Data
mean_charges <- mean(train$Charges)
sd_charges <- sd(train$Charges)
test$scaled_charges <- scale(test$Charges, center = mean_charges, scale = sd_charges)

# Predictions & Residuals for Model 1 
# Model 1: Log Transformation of Charges
train$log_charges <- log(train$Charges)
model_log <- lm(log_charges ~ ., data = train)

# Predictions
predictions_model1 <- exp(predict(model_log, newdata = test))

# Residuals
residuals_model1 <- test$Charges - predictions_model1

# Squared residuals
squared_residuals_model1 <- residuals_model1^2

# Absolute residuals
absolute_residuals_model1 <- abs(residuals_model1)

# MSE, RMSE, and MAE for Model 1
mse_model1 <- mean(squared_residuals_model1)
rmse_model1 <- sqrt(mse_model1)
mae_model1 <- mean(absolute_residuals_model1)

## Predictions & Residuals for Model 2
# Remove log_charges from train and test datasets
train$log_charges <- NULL
test$log_charges <- NULL

# Fit Model 2: Square Root Transformation of Charges
train$sqrt_charges <- sqrt(train$Charges)
model_sqrt <- lm(sqrt_charges ~ ., data = train)

# Predictions
predictions_model2 <- predict(model_sqrt, newdata = test)^2

# Residuals
residuals_model2 <- test$Charges - predictions_model2

# Squared residuals
squared_residuals_model2 <- residuals_model2^2

# Absolute residuals
absolute_residuals_model2 <- abs(residuals_model2)

# MSE, RMSE, and MAE for Model 2
mse_model2 <- mean(squared_residuals_model2)
rmse_model2 <- sqrt(mse_model2)
mae_model2 <- mean(absolute_residuals_model2)

# Compare the performance measures
comparison_data <- data.frame(
  Model = c("Model 1", "Model 2"),
  MSE = c(mse_model1, mse_model2),
  RMSE = c(rmse_model1, rmse_model2),
  MAE = c(mae_model1, mae_model2)
)

print(comparison_data)

# Comparison data
comparison_data <- data.frame(
  Model = c("Model 1", "Model 2"),
  MSE = c(353787090, 10600468),
  RMSE = c(18809.229, 3255.836),
  MAE = c(6741.114, 1528.813)
)

# Convert 'Model' column to factor
comparison_data$Model <- factor(comparison_data$Model)

# Reshape the data for ggplot2
comparison_data_long <- tidyr::gather(comparison_data, Metric, Value, -Model)

# Create a grouped barplot
ggplot(comparison_data_long, aes(x = Model, y = log(Value + 1), fill = Metric)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7) +
  labs(title = "Performance Measures Comparison",
       y = "Log(Value + 1)",
       x = "Model",
       fill = "Metric") +
  scale_y_continuous(labels = scales::comma) +  # Format y-axis labels
  theme_minimal()
```

If we break down each of these performance measures, we see that:

-   Model 2 has a **significantly lower MSE** than Model 1, suggesting it performs better in minimizing squared differences between predicted & actual charges.

-   Model 2 also has a **lower RMSE** than Model 1, which suggests it provides more accurate predictions with smaller errors.

-   Model 2 demonstrates a **smaller MAE** in it's predictions as well, which signifies smaller absolute errors and more accuracy overall.

Therefore, we've determined that Model 2 appears to be the better choice for short-term predictive accuracy, as it consistently exhibits lower values across all three performance measures (MAE, MSE, RMSE).

## Question 6

Provide interpretations of the coefficients, do the signs make sense? Perform marginal change analysis (thing 2) on the independent variables.

```{r}
summary(model_log)
summary(model_sqrt)

##See notes below for interpretations

# Marginal Change Analysis - Model 1: Log Transformation of Charges
coefficients_model1 <- coef(model_log)
marginal_change_model1 <- exp(coefficients_model1)
print(marginal_change_model1)

# Marginal Change Analysis - Model 2: Square Root Transformation of Charges
coefficients_model2 <- coef(model_sqrt)
marginal_change_model2 <- sqrt(coefficients_model2)
marginal_change_model2[is.nan(marginal_change_model2)] <- 0
print(marginal_change_model2)
```

**Model 1:**\
Intercept (7.705e+00) - This is expected when all other variables are 0\
A one-unit increase is associated with Charges, Age, BMI, and Children\
Being female and a smoker are both associated with a decrease in log(Charges).\
Being in Winter Springs, Winter Park or Oviedo are all associated with an increase in log(Charges).\
And last, scaled_charges is not defined due to singularities, so it is considered NA.

In general, the signs of these coefficients make sense. For example, being a smoker is associated with having a negative change in log(Charges), which suggests that smokers typically have lower logged charges.

**Model 2**:\
Very similar in regards to interpretations, with the only difference being that Winter Park is associated with a decrease. All others are essentially the same.

## Question 7

An eager insurance representative comes back with five potential clients. Using the better of the two models selected above, provide the prediction intervals for the five potential clients using the information provided by the insurance rep.

| Customer | Age | BMI | Female | Children | Smoker | City           |
|----------|-----|-----|--------|----------|--------|----------------|
| 1        | 60  | 22  | 1      | 0        | 0      | Oviedo         |
| 2        | 40  | 30  | 0      | 1        | 0      | Sanford        |
| 3        | 25  | 25  | 0      | 0        | 1      | Winter Park    |
| 4        | 33  | 35  | 1      | 2        | 0      | Winter Springs |
| 5        | 45  | 27  | 1      | 3        | 0      | Oviedo         |

```{r}
#
```

## Question 8

The owner notices that some of the predictions are wider than others, explain why.

## Question 9

Are there any prediction problems that occur with the five potential clients? If so, explain.
